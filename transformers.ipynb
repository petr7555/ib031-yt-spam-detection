{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "express-madison",
   "metadata": {},
   "source": [
    "# Transformers library\n",
    "We will take advantage of custom transformers. This way, it is easy to use them in pipelines both for training and testing. We can easily select a subset of transformations and vary transformations based on used model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "wrong-vessel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local\n",
    "from ipynb.fs.full.data_loader import load_train_test_all_cols_data\n",
    "\n",
    "# Math and data stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Language stuff\n",
    "from pymagnitude import Magnitude, MagnitudeUtils\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "\n",
    "# Other\n",
    "import html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-oregon",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "composed-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = load_train_test_all_cols_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-laundry",
   "metadata": {},
   "source": [
    "## DenseTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "entertaining-corrections",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseTransformer(TransformerMixin):\n",
    "    \"\"\"\n",
    "    Makes sparse arrays dense.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense() # toarray() works too"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-jesus",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-raleigh",
   "metadata": {},
   "source": [
    "## FeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "driving-moore",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>AUTHOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-22 11:46:35.988</td>\n",
       "      <td>Sonny Carter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-09-09 17:34:07.052</td>\n",
       "      <td>Lizzy Molly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-26 02:27:43.254</td>\n",
       "      <td>Warcorpse666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-09-03 16:32:59.000</td>\n",
       "      <td>Santeri Saariokari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-11-06 19:50:16.000</td>\n",
       "      <td>Quinho Divulgaçoes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     DATE              AUTHOR\n",
       "0 2015-05-22 11:46:35.988        Sonny Carter\n",
       "1 2013-09-09 17:34:07.052         Lizzy Molly\n",
       "2 2015-05-26 02:27:43.254        Warcorpse666\n",
       "3 2014-09-03 16:32:59.000  Santeri Saariokari\n",
       "4 2014-11-06 19:50:16.000  Quinho Divulgaçoes"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Selects a subset of features based on column names or data type.\n",
    "    If both `columns` and `dtype_include` are given, union of selected columns is returned.\n",
    "    \"\"\"\n",
    "    def __init__(self, columns=[], dtype_include=None):\n",
    "        self.columns = columns\n",
    "        self.dtype_include = dtype_include\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        if self.dtype_include is not None:\n",
    "            self.columns.extend(X.select_dtypes(self.dtype_include).columns)\n",
    "        return X[set(self.columns)]\n",
    "\n",
    "# DEMO 1\n",
    "transformed = FeatureSelector([\"AUTHOR\", \"DATE\"]).transform(train_X)\n",
    "transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stopped-visitor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>INTERPRET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z13wxtdpeznid12et23ogtd4zoyvzbnoz04</td>\n",
       "      <td>Sonny Carter</td>\n",
       "      <td>I love this song sooooooooooooooo much﻿</td>\n",
       "      <td>eminem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY</td>\n",
       "      <td>Lizzy Molly</td>\n",
       "      <td>PLEASE CHECK OUT MY VIDEO CALLED &amp;quot;WE LOVE...</td>\n",
       "      <td>shakira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z13uutbriumnuj3rq04ccbvqlwjuj1srhyk0k</td>\n",
       "      <td>Warcorpse666</td>\n",
       "      <td>sorry but eminmem is a worthless wife beating ...</td>\n",
       "      <td>eminem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z121gbuy2unhc5m4n04cf3kyslqhepeqgvo0k</td>\n",
       "      <td>Santeri Saariokari</td>\n",
       "      <td>Hey guys go to check my video name \"growtopia ...</td>\n",
       "      <td>katy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z133hdqrqpukup0lp22chhoaztrhvxov5</td>\n",
       "      <td>Quinho Divulgaçoes</td>\n",
       "      <td>me segue ha  https://www.facebook.com/marcos.s...</td>\n",
       "      <td>katy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    COMMENT_ID              AUTHOR  \\\n",
       "0          z13wxtdpeznid12et23ogtd4zoyvzbnoz04        Sonny Carter   \n",
       "1  _2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY         Lizzy Molly   \n",
       "2        z13uutbriumnuj3rq04ccbvqlwjuj1srhyk0k        Warcorpse666   \n",
       "3        z121gbuy2unhc5m4n04cf3kyslqhepeqgvo0k  Santeri Saariokari   \n",
       "4            z133hdqrqpukup0lp22chhoaztrhvxov5  Quinho Divulgaçoes   \n",
       "\n",
       "                                             CONTENT INTERPRET  \n",
       "0            I love this song sooooooooooooooo much﻿    eminem  \n",
       "1  PLEASE CHECK OUT MY VIDEO CALLED &quot;WE LOVE...   shakira  \n",
       "2  sorry but eminmem is a worthless wife beating ...    eminem  \n",
       "3  Hey guys go to check my video name \"growtopia ...      katy  \n",
       "4  me segue ha  https://www.facebook.com/marcos.s...      katy  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEMO 2\n",
    "transformed = FeatureSelector(dtype_include=\"string\").transform(train_X)\n",
    "transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "logical-bouquet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>INTERPRET</th>\n",
       "      <th>AUTHOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-22 11:46:35.988</td>\n",
       "      <td>eminem</td>\n",
       "      <td>Sonny Carter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-09-09 17:34:07.052</td>\n",
       "      <td>shakira</td>\n",
       "      <td>Lizzy Molly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-26 02:27:43.254</td>\n",
       "      <td>eminem</td>\n",
       "      <td>Warcorpse666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-09-03 16:32:59.000</td>\n",
       "      <td>katy</td>\n",
       "      <td>Santeri Saariokari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-11-06 19:50:16.000</td>\n",
       "      <td>katy</td>\n",
       "      <td>Quinho Divulgaçoes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     DATE INTERPRET              AUTHOR\n",
       "0 2015-05-22 11:46:35.988    eminem        Sonny Carter\n",
       "1 2013-09-09 17:34:07.052   shakira         Lizzy Molly\n",
       "2 2015-05-26 02:27:43.254    eminem        Warcorpse666\n",
       "3 2014-09-03 16:32:59.000      katy  Santeri Saariokari\n",
       "4 2014-11-06 19:50:16.000      katy  Quinho Divulgaçoes"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEMO 3\n",
    "transformed = FeatureSelector(columns=[\"INTERPRET\", \"AUTHOR\"], dtype_include=\"datetime\").transform(train_X)\n",
    "transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-sending",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-ordering",
   "metadata": {},
   "source": [
    "## WordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "considered-diploma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 30, 300)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class WordEmbeddingsSeries(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    ! Works with Series, not DataFrame !\n",
    "    For each row in series, which contains a sentence, \n",
    "    it embeds the words in the series into 300 dimensional vectors (one vector for each word).\n",
    "    \"\"\"\n",
    "    def __init__(self, vectors):\n",
    "        super().__init__()\n",
    "        self.vectors = vectors\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        tokenized = [word_tokenize(line) for line in X]\n",
    "        return self.vectors.query(tokenized)\n",
    "    \n",
    "# DEMO\n",
    "vectors = Magnitude(MagnitudeUtils.download_model('fasttext/medium/wiki-news-300d-1M'), pad_to_length=30)\n",
    "transformed = WordEmbeddingsSeries(vectors).transform(train_X[\"CONTENT\"][:20])\n",
    "transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-manual",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-listing",
   "metadata": {},
   "source": [
    "## WordEmbeddingsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "lesbian-episode",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1249, 602)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class WordEmbeddingsDF(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    For each column (given in constructor or all columns if not specified),\n",
    "    computes word embedddings of values in the column split with nltk.word_tokenize.\n",
    "    The mean of these word embeddings is then computed, giving 300 dimensional vector for each row.\n",
    "    This vector is then appended to the dataframe as 300 new columns.\n",
    "    \"\"\"\n",
    "    def __init__(self, columns=None):\n",
    "        super().__init__()\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        i = 0\n",
    "        # encode all columns by default\n",
    "        if self.columns is None:\n",
    "            self.columns = X.columns\n",
    "\n",
    "        for col in self.columns:\n",
    "            tokenized = [word_tokenize(line) for line in X[col]]\n",
    "            mean = np.mean(vectors.query(tokenized), axis=1)\n",
    "            for j in range(300):\n",
    "                X[f\"{i}_EMBEDDED\"] = mean[:,j]\n",
    "                i += 1\n",
    "                \n",
    "        return X\n",
    "    \n",
    "transformed = WordEmbeddingsDF().transform(train_X[[\"AUTHOR\", \"CONTENT\"]])\n",
    "transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-heating",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-consideration",
   "metadata": {},
   "source": [
    "## ExplorativeTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "genetic-repository",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>INTERPRET</th>\n",
       "      <th>HAS_LINK</th>\n",
       "      <th>NOT_UNIQUE_AUTHOR</th>\n",
       "      <th>NULL_IN_DATE_TIME</th>\n",
       "      <th>SUSPICIOUS_WORDS_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z13wxtdpeznid12et23ogtd4zoyvzbnoz04</td>\n",
       "      <td>Sonny Carter</td>\n",
       "      <td>2015-05-22 11:46:35.988</td>\n",
       "      <td>I love this song sooooooooooooooo much﻿</td>\n",
       "      <td>eminem</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY</td>\n",
       "      <td>Lizzy Molly</td>\n",
       "      <td>2013-09-09 17:34:07.052</td>\n",
       "      <td>PLEASE CHECK OUT MY VIDEO CALLED &amp;quot;WE LOVE...</td>\n",
       "      <td>shakira</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z13uutbriumnuj3rq04ccbvqlwjuj1srhyk0k</td>\n",
       "      <td>Warcorpse666</td>\n",
       "      <td>2015-05-26 02:27:43.254</td>\n",
       "      <td>sorry but eminmem is a worthless wife beating ...</td>\n",
       "      <td>eminem</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z121gbuy2unhc5m4n04cf3kyslqhepeqgvo0k</td>\n",
       "      <td>Santeri Saariokari</td>\n",
       "      <td>2014-09-03 16:32:59.000</td>\n",
       "      <td>Hey guys go to check my video name \"growtopia ...</td>\n",
       "      <td>katy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z133hdqrqpukup0lp22chhoaztrhvxov5</td>\n",
       "      <td>Quinho Divulgaçoes</td>\n",
       "      <td>2014-11-06 19:50:16.000</td>\n",
       "      <td>me segue ha  https://www.facebook.com/marcos.s...</td>\n",
       "      <td>katy</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    COMMENT_ID              AUTHOR  \\\n",
       "0          z13wxtdpeznid12et23ogtd4zoyvzbnoz04        Sonny Carter   \n",
       "1  _2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY         Lizzy Molly   \n",
       "2        z13uutbriumnuj3rq04ccbvqlwjuj1srhyk0k        Warcorpse666   \n",
       "3        z121gbuy2unhc5m4n04cf3kyslqhepeqgvo0k  Santeri Saariokari   \n",
       "4            z133hdqrqpukup0lp22chhoaztrhvxov5  Quinho Divulgaçoes   \n",
       "\n",
       "                     DATE                                            CONTENT  \\\n",
       "0 2015-05-22 11:46:35.988            I love this song sooooooooooooooo much﻿   \n",
       "1 2013-09-09 17:34:07.052  PLEASE CHECK OUT MY VIDEO CALLED &quot;WE LOVE...   \n",
       "2 2015-05-26 02:27:43.254  sorry but eminmem is a worthless wife beating ...   \n",
       "3 2014-09-03 16:32:59.000  Hey guys go to check my video name \"growtopia ...   \n",
       "4 2014-11-06 19:50:16.000  me segue ha  https://www.facebook.com/marcos.s...   \n",
       "\n",
       "  INTERPRET  HAS_LINK  NOT_UNIQUE_AUTHOR  NULL_IN_DATE_TIME  \\\n",
       "0    eminem         0                  0                  0   \n",
       "1   shakira         0                  0                  0   \n",
       "2    eminem         0                  0                  0   \n",
       "3      katy         0                  0                  0   \n",
       "4      katy         2                  0                  0   \n",
       "\n",
       "   SUSPICIOUS_WORDS_COUNT  \n",
       "0                       0  \n",
       "1                       3  \n",
       "2                       0  \n",
       "3                       3  \n",
       "4                       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ExplorativeTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.duplicated_and_spammers = 0\n",
    "        self.duplicated_and_not_spammers = 0\n",
    "        self.not_unique_authors = set()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        \n",
    "        stop = stopwords.words('english')\n",
    "\n",
    "        author_set = set()\n",
    "        for author in X[\"AUTHOR\"]:\n",
    "            if author in author_set:\n",
    "                self.not_unique_authors.add(author)\n",
    "            author_set.add(author)\n",
    "            \n",
    "        # are all duplicated authors spammers?\n",
    "        for index, row in X.iterrows():\n",
    "            if row[\"AUTHOR\"] in self.not_unique_authors and y[index] == 1:\n",
    "                self.duplicated_and_spammers += 1\n",
    "            if row[\"AUTHOR\"] in self.not_unique_authors and y[index] == 0:\n",
    "                self.duplicated_and_not_spammers += 1\n",
    "        \n",
    "        \"\"\"\n",
    "        Creates 2 dictionaries: spam_dic and ham_dict, one that counts occurence of each word in spam comments, \n",
    "        other counts occurence of each word in ham comments.\n",
    "        Further, only those words that are repeated more than 15 times are left in ham_dict, \n",
    "        and those repeated more than 35 times in spam_dict.\n",
    "        Numbers are chosen like that, because I wanted to empahsise, that it is more importatnt to not mark as spam sth.,\n",
    "        that is not spam, than the other way around.\n",
    "        The last step is to keep only those words in spam_dict that are not in ham_dict and are not stop_words.\n",
    "        \"\"\"\n",
    "\n",
    "        self.spam_dict = self.get_suspicious_words(X, y, 1)\n",
    "        ham_dict = self.get_suspicious_words(X, y, 0)\n",
    "        my_inverted_dict_spam = dict(map(reversed, self.spam_dict.items()))\n",
    "        my_inverted_dict_ham = dict(map(reversed, ham_dict.items()))\n",
    "        suspicious_spam = []\n",
    "        suspicious_ham = []\n",
    "\n",
    "        for key in my_inverted_dict_spam:\n",
    "            if key > 15 and my_inverted_dict_spam[key] not in stop:\n",
    "                suspicious_spam.append(my_inverted_dict_spam[key])\n",
    "\n",
    "        for key in my_inverted_dict_ham:\n",
    "            if key > 35 and my_inverted_dict_ham[key] not in stop:\n",
    "                suspicious_ham.append(my_inverted_dict_ham[key])\n",
    "\n",
    "        # remove all from spam that is in ham\n",
    "        self.suspicious_words_list = []\n",
    "        for word in suspicious_spam:\n",
    "            if word not in suspicious_ham:\n",
    "                self.suspicious_words_list.append(word)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"HAS_LINK\"] = np.where(X['CONTENT'].str.contains('http') |\n",
    "                                  X['CONTENT'].str.contains('//'), 2, 0)\n",
    "    \n",
    "        X[\"NOT_UNIQUE_AUTHOR\"] = np.where(X['AUTHOR'].str in self.not_unique_authors, self.duplicated_and_not_spammers\n",
    "                                           // self.duplicated_and_spammers, 0)\n",
    "\n",
    "        X[\"NULL_IN_DATE_TIME\"] = np.where(X[\"DATE\"].isna(), 2, 0)\n",
    "                \n",
    "        result = []\n",
    "        for index, row in X.iterrows():\n",
    "            suspicious_counter = 0\n",
    "            for word in self.suspicious_words_list:\n",
    "                my_row = row[\"CONTENT\"].lower().split()\n",
    "                if word in my_row:\n",
    "                    suspicious_counter += self.spam_dict[word.lower()] // 100\n",
    "            result.append(suspicious_counter)\n",
    "\n",
    "        X[\"SUSPICIOUS_WORDS_COUNT\"] = result\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def get_suspicious_words(self, X, y, num):\n",
    "        result = {}\n",
    "        for index, row in X.iterrows():\n",
    "            if y[index] != num:\n",
    "                continue\n",
    "            words = (row[\"CONTENT\"].lower()).split()\n",
    "            for word in words:\n",
    "                if word in result:\n",
    "                    result[word] += 1\n",
    "                else:\n",
    "                    result[word] = 1\n",
    "                    \n",
    "        return result\n",
    "\n",
    "# DEMO\n",
    "transformed = ExplorativeTransformer().fit_transform(train_X, train_y)\n",
    "transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-poker",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-lemon",
   "metadata": {},
   "source": [
    "## AddMissingDateColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "suburban-pricing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>INTERPRET</th>\n",
       "      <th>DATE_MISSING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>_2viQ_Qnc6_FlLJN0izQaKVQNe6LGDmPZMmkVDjjymE</td>\n",
       "      <td>Neeru bala</td>\n",
       "      <td>2013-09-05 23:07:09.056</td>\n",
       "      <td>Hi.. Everyone.. If anyone after real online wo...</td>\n",
       "      <td>shakira</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>LneaDw26bFsltJodWnZAafXscqrATBuKDM8-8lA4TQE</td>\n",
       "      <td>miamiscraziest</td>\n",
       "      <td>NaT</td>\n",
       "      <td>LADIES!!! -----&amp;gt;&amp;gt; If you have a broken h...</td>\n",
       "      <td>eminem</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       COMMENT_ID          AUTHOR  \\\n",
       "1244  _2viQ_Qnc6_FlLJN0izQaKVQNe6LGDmPZMmkVDjjymE      Neeru bala   \n",
       "1245  LneaDw26bFsltJodWnZAafXscqrATBuKDM8-8lA4TQE  miamiscraziest   \n",
       "\n",
       "                        DATE  \\\n",
       "1244 2013-09-05 23:07:09.056   \n",
       "1245                     NaT   \n",
       "\n",
       "                                                CONTENT INTERPRET  \\\n",
       "1244  Hi.. Everyone.. If anyone after real online wo...   shakira   \n",
       "1245  LADIES!!! -----&gt;&gt; If you have a broken h...    eminem   \n",
       "\n",
       "      DATE_MISSING  \n",
       "1244         False  \n",
       "1245          True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AddMissingDateColumn(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Adds boolean column if DATE value is missing.\n",
    "    The model should then understand that True most likely means spam.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # do not modify the original dataset\n",
    "        X = X.copy()\n",
    "        X[\"DATE_MISSING\"] = X.DATE.isna()\n",
    "        return X\n",
    "    \n",
    "# DEMO\n",
    "transformed = AddMissingDateColumn().transform(train_X)\n",
    "transformed[1244:1246]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-space",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-lying",
   "metadata": {},
   "source": [
    "## AddLongCommentColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "wireless-duplicate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>INTERPRET</th>\n",
       "      <th>LONG_COMMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z13wxtdpeznid12et23ogtd4zoyvzbnoz04</td>\n",
       "      <td>Sonny Carter</td>\n",
       "      <td>2015-05-22 11:46:35.988</td>\n",
       "      <td>I love this song sooooooooooooooo much﻿</td>\n",
       "      <td>eminem</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY</td>\n",
       "      <td>Lizzy Molly</td>\n",
       "      <td>2013-09-09 17:34:07.052</td>\n",
       "      <td>PLEASE CHECK OUT MY VIDEO CALLED &amp;quot;WE LOVE...</td>\n",
       "      <td>shakira</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    COMMENT_ID        AUTHOR  \\\n",
       "0          z13wxtdpeznid12et23ogtd4zoyvzbnoz04  Sonny Carter   \n",
       "1  _2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY   Lizzy Molly   \n",
       "\n",
       "                     DATE                                            CONTENT  \\\n",
       "0 2015-05-22 11:46:35.988            I love this song sooooooooooooooo much﻿   \n",
       "1 2013-09-09 17:34:07.052  PLEASE CHECK OUT MY VIDEO CALLED &quot;WE LOVE...   \n",
       "\n",
       "  INTERPRET  LONG_COMMENT  \n",
       "0    eminem         False  \n",
       "1   shakira          True  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AddLongCommentColumn(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Adds boolean column if CONTENT is longer or equal to 50 charcters.\n",
    "    The model should then understand that True most likely means spam.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"LONG_COMMENT\"] = X.CONTENT.str.len() >= 50\n",
    "        return X\n",
    "\n",
    "# DEMO\n",
    "transformed = AddLongCommentColumn().transform(train_X)\n",
    "transformed[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-accountability",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-enforcement",
   "metadata": {},
   "source": [
    "## AddContainsCheckColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "front-piece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>INTERPRET</th>\n",
       "      <th>CONTAINS_CHECK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z13uutbriumnuj3rq04ccbvqlwjuj1srhyk0k</td>\n",
       "      <td>Warcorpse666</td>\n",
       "      <td>2015-05-26 02:27:43.254</td>\n",
       "      <td>sorry but eminmem is a worthless wife beating ...</td>\n",
       "      <td>eminem</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z121gbuy2unhc5m4n04cf3kyslqhepeqgvo0k</td>\n",
       "      <td>Santeri Saariokari</td>\n",
       "      <td>2014-09-03 16:32:59.000</td>\n",
       "      <td>Hey guys go to check my video name \"growtopia ...</td>\n",
       "      <td>katy</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              COMMENT_ID              AUTHOR  \\\n",
       "2  z13uutbriumnuj3rq04ccbvqlwjuj1srhyk0k        Warcorpse666   \n",
       "3  z121gbuy2unhc5m4n04cf3kyslqhepeqgvo0k  Santeri Saariokari   \n",
       "\n",
       "                     DATE                                            CONTENT  \\\n",
       "2 2015-05-26 02:27:43.254  sorry but eminmem is a worthless wife beating ...   \n",
       "3 2014-09-03 16:32:59.000  Hey guys go to check my video name \"growtopia ...   \n",
       "\n",
       "  INTERPRET  CONTAINS_CHECK  \n",
       "2    eminem           False  \n",
       "3      katy            True  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AddContainsCheckColumn(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Adds boolean column if CONTENT contains 'check'.\n",
    "    The model should then understand that True most likely means spam.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"CONTAINS_CHECK\"] = X.CONTENT.str.contains(\"check\")\n",
    "        return X\n",
    "\n",
    "# DEMO\n",
    "transformed = AddContainsCheckColumn().transform(train_X)\n",
    "transformed[2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-pride",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-stevens",
   "metadata": {},
   "source": [
    "## AddMultipleCommentsColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "selective-renewal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>INTERPRET</th>\n",
       "      <th>MULTIPLE_COMMENTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY</td>\n",
       "      <td>Lizzy Molly</td>\n",
       "      <td>2013-09-09 17:34:07.052</td>\n",
       "      <td>PLEASE CHECK OUT MY VIDEO CALLED &amp;quot;WE LOVE...</td>\n",
       "      <td>shakira</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    COMMENT_ID       AUTHOR  \\\n",
       "1  _2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY  Lizzy Molly   \n",
       "\n",
       "                     DATE                                            CONTENT  \\\n",
       "1 2013-09-09 17:34:07.052  PLEASE CHECK OUT MY VIDEO CALLED &quot;WE LOVE...   \n",
       "\n",
       "  INTERPRET  MULTIPLE_COMMENTS  \n",
       "1   shakira              False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AddMultipleCommentsColumn(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Adds boolean column if author posted multiple comments.\n",
    "    The model should then understand that True most likely means spam.\n",
    "    \n",
    "    Looks also into data it has been fit on.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.prev_X = X.copy()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        joined = pd.concat([X, self.prev_X])\n",
    "        joined.drop_duplicates(inplace=True)\n",
    "        X[\"MULTIPLE_COMMENTS\"] = joined.duplicated(subset=[\"AUTHOR\"], keep=False)[:len(X)]\n",
    "        return X\n",
    "    \n",
    "# DEMO\n",
    "mollys = train_X[train_X.AUTHOR == \"Lizzy Molly\"]\n",
    "admc = AddMultipleCommentsColumn()\n",
    "admc.fit_transform(mollys[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "filled-woman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>INTERPRET</th>\n",
       "      <th>MULTIPLE_COMMENTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>LneaDw26bFuhuiZ8uX6C-qYLIsOFj9BIWtKWtCz870c</td>\n",
       "      <td>Lizzy Molly</td>\n",
       "      <td>NaT</td>\n",
       "      <td>PLEASE CHECK OUT MY VIDEO CALLED &amp;quot;WE LOVE...</td>\n",
       "      <td>eminem</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      COMMENT_ID       AUTHOR DATE  \\\n",
       "841  LneaDw26bFuhuiZ8uX6C-qYLIsOFj9BIWtKWtCz870c  Lizzy Molly  NaT   \n",
       "\n",
       "                                               CONTENT INTERPRET  \\\n",
       "841  PLEASE CHECK OUT MY VIDEO CALLED &quot;WE LOVE...    eminem   \n",
       "\n",
       "     MULTIPLE_COMMENTS  \n",
       "841               True  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = admc.transform(mollys[1:2])\n",
    "transformed[transformed.AUTHOR == \"Lizzy Molly\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-productivity",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-rogers",
   "metadata": {},
   "source": [
    "## AddMultipleCommentsSameVideoColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "pressed-neighborhood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>INTERPRET</th>\n",
       "      <th>MULTIPLE_COMMENTS_SAME_VIDEO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY</td>\n",
       "      <td>Lizzy Molly</td>\n",
       "      <td>2013-09-09 17:34:07.052</td>\n",
       "      <td>PLEASE CHECK OUT MY VIDEO CALLED &amp;quot;WE LOVE...</td>\n",
       "      <td>shakira</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>LneaDw26bFuhuiZ8uX6C-qYLIsOFj9BIWtKWtCz870c</td>\n",
       "      <td>Lizzy Molly</td>\n",
       "      <td>NaT</td>\n",
       "      <td>PLEASE CHECK OUT MY VIDEO CALLED &amp;quot;WE LOVE...</td>\n",
       "      <td>eminem</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      COMMENT_ID       AUTHOR  \\\n",
       "1    _2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY  Lizzy Molly   \n",
       "841  LneaDw26bFuhuiZ8uX6C-qYLIsOFj9BIWtKWtCz870c  Lizzy Molly   \n",
       "\n",
       "                       DATE  \\\n",
       "1   2013-09-09 17:34:07.052   \n",
       "841                     NaT   \n",
       "\n",
       "                                               CONTENT INTERPRET  \\\n",
       "1    PLEASE CHECK OUT MY VIDEO CALLED &quot;WE LOVE...   shakira   \n",
       "841  PLEASE CHECK OUT MY VIDEO CALLED &quot;WE LOVE...    eminem   \n",
       "\n",
       "     MULTIPLE_COMMENTS_SAME_VIDEO  \n",
       "1                           False  \n",
       "841                         False  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AddMultipleCommentsSameVideoColumn(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Adds boolean column if author posted multiple comments for the same video.\n",
    "    The model should then understand that True most likely means spam.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"MULTIPLE_COMMENTS_SAME_VIDEO\"] = X.duplicated(subset=[\"AUTHOR\", \"INTERPRET\"], keep=False)\n",
    "        return X\n",
    "    \n",
    "# DEMO    \n",
    "transformed = AddMultipleCommentsSameVideoColumn().transform(train_X)\n",
    "transformed[transformed.AUTHOR == \"Lizzy Molly\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-macintosh",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-cardiff",
   "metadata": {},
   "source": [
    "## AddContainsHttpColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "quiet-proportion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>INTERPRET</th>\n",
       "      <th>CONTAINS_HTTP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z121gbuy2unhc5m4n04cf3kyslqhepeqgvo0k</td>\n",
       "      <td>Santeri Saariokari</td>\n",
       "      <td>2014-09-03 16:32:59</td>\n",
       "      <td>Hey guys go to check my video name \"growtopia ...</td>\n",
       "      <td>katy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z133hdqrqpukup0lp22chhoaztrhvxov5</td>\n",
       "      <td>Quinho Divulgaçoes</td>\n",
       "      <td>2014-11-06 19:50:16</td>\n",
       "      <td>me segue ha  https://www.facebook.com/marcos.s...</td>\n",
       "      <td>katy</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              COMMENT_ID              AUTHOR  \\\n",
       "3  z121gbuy2unhc5m4n04cf3kyslqhepeqgvo0k  Santeri Saariokari   \n",
       "4      z133hdqrqpukup0lp22chhoaztrhvxov5  Quinho Divulgaçoes   \n",
       "\n",
       "                 DATE                                            CONTENT  \\\n",
       "3 2014-09-03 16:32:59  Hey guys go to check my video name \"growtopia ...   \n",
       "4 2014-11-06 19:50:16  me segue ha  https://www.facebook.com/marcos.s...   \n",
       "\n",
       "  INTERPRET  CONTAINS_HTTP  \n",
       "3      katy          False  \n",
       "4      katy           True  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AddContainsHttpColumn(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Adds boolean column if CONTENT contains a link.\n",
    "    The model should then understand that True most likely means spam.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"CONTAINS_HTTP\"] = X.CONTENT.str.contains(\"http\")\n",
    "        return X\n",
    "    \n",
    "# DEMO    \n",
    "transformed = AddContainsHttpColumn().transform(train_X)\n",
    "transformed[3:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-display",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-diversity",
   "metadata": {},
   "source": [
    "## AddTimeColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "purple-triangle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>INTERPRET</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z13wxtdpeznid12et23ogtd4zoyvzbnoz04</td>\n",
       "      <td>Sonny Carter</td>\n",
       "      <td>2015-05-22 11:46:35.988</td>\n",
       "      <td>I love this song sooooooooooooooo much﻿</td>\n",
       "      <td>eminem</td>\n",
       "      <td>11:46:35.988000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            COMMENT_ID        AUTHOR                    DATE  \\\n",
       "0  z13wxtdpeznid12et23ogtd4zoyvzbnoz04  Sonny Carter 2015-05-22 11:46:35.988   \n",
       "\n",
       "                                   CONTENT INTERPRET             TIME  \n",
       "0  I love this song sooooooooooooooo much﻿    eminem  11:46:35.988000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AddTimeColumn(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Adds time column.\n",
    "    Hypothesis: spams are posted at night, or, on the contrary, spams are posted during main working hours. Let the model decide...\n",
    "    This probably won't work, because the dates are most likely relative to the time zone, where they were collected.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"TIME\"] = X.DATE.dt.time\n",
    "        return X\n",
    "    \n",
    "# DEMO    \n",
    "transformed = AddTimeColumn().transform(train_X)\n",
    "transformed[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-rugby",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-phenomenon",
   "metadata": {},
   "source": [
    "## HtmlUnescaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dense-consistency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  <a href=\"http://www.youtube.com/watch?v=KQ6zr6kCPj8&amp;t=2m19s\">2:19</a> best part﻿\n",
      "After:  <a href=\"http://www.youtube.com/watch?v=KQ6zr6kCPj8&t=2m19s\">2:19</a> best part﻿\n"
     ]
    }
   ],
   "source": [
    "class HtmlUnescaper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    For example, `&amp;` is escaped ampersand. Unescape it and other characters as well.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"CONTENT\"] = X[\"CONTENT\"].apply(html.unescape)\n",
    "        return X\n",
    "    \n",
    "# DEMO    \n",
    "print(\"Before: \", train_X.CONTENT[97])\n",
    "transformed = HtmlUnescaper().transform(train_X)\n",
    "print(\"After: \", transformed.CONTENT[97])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-inclusion",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-break",
   "metadata": {},
   "source": [
    "## BOMRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "speaking-latest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Before: <a href=\"http://www.youtube.com/watch?v=KQ6zr6kCPj8&amp;t=2m19s\">2:19</a> best part\\ufeff'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BOMRemover(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Remove Byte Order Mark from comments.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"CONTENT\"] = X[\"CONTENT\"].str.replace(\"\\ufeff\", \"\", regex=False)\n",
    "        return X\n",
    "\n",
    "# DEMO\n",
    "\"Before: \" + train_X.CONTENT.loc[97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "naked-winning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'After: <a href=\"http://www.youtube.com/watch?v=KQ6zr6kCPj8&amp;t=2m19s\">2:19</a> best part'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = BOMRemover().transform(train_X)\n",
    "\"After: \" + transformed.CONTENT.loc[97]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-intake",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-prefix",
   "metadata": {},
   "source": [
    "## AnchorTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "english-cooking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: <a href=\"http://www.youtube.com/watch?v=KQ6zr6kCPj8&amp;t=2m19s\">2:19</a> best part﻿\n",
      "After: anchortag best part﻿\n"
     ]
    }
   ],
   "source": [
    "class AnchorTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transforms all anchor tags into one keyword. \n",
    "    The model will figure out, that the presence of this keyword probably means spam.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"CONTENT\"] = X[\"CONTENT\"].str.replace(\"<a.+>\", \"anchortag\", regex=True)\n",
    "        return X\n",
    "    \n",
    "# DEMO\n",
    "print(\"Before: \" + train_X.CONTENT.loc[97])\n",
    "transformed = AnchorTransformer().transform(train_X)\n",
    "print(\"After: \" + transformed.CONTENT.loc[97])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-cache",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-valentine",
   "metadata": {},
   "source": [
    "## AddContainsAnchorTagColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "israeli-annex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: <a href=\"http://www.youtube.com/watch?v=KQ6zr6kCPj8&amp;t=2m19s\">2:19</a> best part﻿\n",
      "After:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "COMMENT_ID             z13uwn2heqndtr5g304ccv5j5kqqzxjadmc0k\n",
       "AUTHOR                                          Corey Wilson\n",
       "DATE                              2015-05-28 21:39:52.376000\n",
       "CONTENT                                           best part﻿\n",
       "INTERPRET                                              lmfao\n",
       "CONTAINS_ANCHOR_TAG                                     True\n",
       "Name: 97, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AddContainsAnchorTagColumn(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Adds new column CONTAINS_ANCHOR_TAG which is True when CONTENT contains <a> tag.\n",
    "    The model should then understand that True most likely means spam.\n",
    "    Removes the link from CONTENT as well.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"CONTAINS_ANCHOR_TAG\"] = X[\"CONTENT\"].str.contains(\"<a.+>\")\n",
    "        X[\"CONTENT\"] = X[\"CONTENT\"].str.replace(\"<a.+>\", \"\", regex=True)\n",
    "        return X\n",
    "    \n",
    "# DEMO\n",
    "print(\"Before: \" + train_X.CONTENT.loc[97])\n",
    "transformed = AddContainsAnchorTagColumn().transform(train_X)\n",
    "print(\"After:\")\n",
    "transformed.loc[97]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-music",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-vietnam",
   "metadata": {},
   "source": [
    "## Lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "supported-lloyd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: Katy Perry is lion﻿\n",
      "After: katy perry is lion﻿\n"
     ]
    }
   ],
   "source": [
    "class Lower(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Makes CONTENT lowercase.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"CONTENT\"] = X[\"CONTENT\"].str.lower()\n",
    "        return X\n",
    "    \n",
    "# DEMO\n",
    "print(\"Before: \" + train_X.CONTENT.loc[5])\n",
    "transformed = Lower().transform(train_X)\n",
    "print(\"After: \" + transformed.CONTENT.loc[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-forward",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-pennsylvania",
   "metadata": {},
   "source": [
    "## UrlTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "senior-treasurer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: follower please https://www.facebook.com/lists/161620527267482﻿\n",
      "Before: /watch?v=aImbWbfQbzg watch and subscrible\n",
      "After: follower please urllink\n",
      "After: urllink watch and subscrible\n"
     ]
    }
   ],
   "source": [
    "class UrlTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transforms all urls into one keyword. \n",
    "    The model will figure out, that the presence of this keyword probably means spam.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"CONTENT\"] = X[\"CONTENT\"].str.replace(r\"\\S*\\.com\\S*|\\S*watch\\?\\S*\", \"urllink\", regex=True)\n",
    "        return X\n",
    "    \n",
    "# DEMO\n",
    "print(\"Before: \" + train_X.CONTENT.loc[1220])\n",
    "print(\"Before: \" + train_X.CONTENT.loc[186])\n",
    "transformed = UrlTransformer().transform(train_X)\n",
    "print(\"After: \" + transformed.CONTENT.loc[1220])\n",
    "print(\"After: \" + transformed.CONTENT.loc[186])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-clone",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-interface",
   "metadata": {},
   "source": [
    "## Debugger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "absolute-punch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    COMMENT_ID              AUTHOR  \\\n",
      "0          z13wxtdpeznid12et23ogtd4zoyvzbnoz04        Sonny Carter   \n",
      "1  _2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY         Lizzy Molly   \n",
      "2        z13uutbriumnuj3rq04ccbvqlwjuj1srhyk0k        Warcorpse666   \n",
      "3        z121gbuy2unhc5m4n04cf3kyslqhepeqgvo0k  Santeri Saariokari   \n",
      "4            z133hdqrqpukup0lp22chhoaztrhvxov5  Quinho Divulgaçoes   \n",
      "\n",
      "                     DATE                                            CONTENT  \\\n",
      "0 2015-05-22 11:46:35.988            I love this song sooooooooooooooo much﻿   \n",
      "1 2013-09-09 17:34:07.052  PLEASE CHECK OUT MY VIDEO CALLED &quot;WE LOVE...   \n",
      "2 2015-05-26 02:27:43.254  sorry but eminmem is a worthless wife beating ...   \n",
      "3 2014-09-03 16:32:59.000  Hey guys go to check my video name \"growtopia ...   \n",
      "4 2014-11-06 19:50:16.000  me segue ha  https://www.facebook.com/marcos.s...   \n",
      "\n",
      "  INTERPRET  \n",
      "0    eminem  \n",
      "1   shakira  \n",
      "2    eminem  \n",
      "3      katy  \n",
      "4      katy  \n"
     ]
    }
   ],
   "source": [
    "class Debugger(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Prints first 5 rows of dataframe\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        print(X[:5])\n",
    "        return X\n",
    "    \n",
    "# DEMO\n",
    "transformed = Debugger().transform(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-chorus",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-cabinet",
   "metadata": {},
   "source": [
    "## ContentCountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "crude-chorus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>INTERPRET</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>002</th>\n",
       "      <th>018</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>ｃｏｍｍｅｎｔ</th>\n",
       "      <th>ｄａｍｎ</th>\n",
       "      <th>ｅｂａｙ</th>\n",
       "      <th>ｆａｎｃy</th>\n",
       "      <th>ｈｔｔｐ</th>\n",
       "      <th>ｉｓ</th>\n",
       "      <th>ｓｈｏｅｃｏｌｌｅｃｔｏｒ314</th>\n",
       "      <th>ｔｈｉｓ</th>\n",
       "      <th>ｕｓｒ</th>\n",
       "      <th>ｗｗｗ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z13ozdmr4lf3uzc5z04cix2zkyjzgvcyemw0k</td>\n",
       "      <td>Carlos Thegamer</td>\n",
       "      <td>2013-12-01 01:20:21.000</td>\n",
       "      <td>subscribe to my channel people :D﻿</td>\n",
       "      <td>psy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z13aznjg2ojwjlknm23yjbt4uniuepuxs04</td>\n",
       "      <td>Dunrell Pinder</td>\n",
       "      <td>2015-05-23 02:57:54.433</td>\n",
       "      <td>i love her﻿</td>\n",
       "      <td>shakira</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z12kil5h2ujlyzgnc23qtzqyokqrc3301</td>\n",
       "      <td>Sinaloence LiveUniverseI</td>\n",
       "      <td>2015-04-29 03:58:06.452</td>\n",
       "      <td>I like This Comment and do not kill :P﻿</td>\n",
       "      <td>lmfao</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13vhvu54u3ewpp5h04ccb4zuoardrmjlyk0k</td>\n",
       "      <td>Ray Benich</td>\n",
       "      <td>2015-06-05 18:05:16.000</td>\n",
       "      <td>The first billion viewed this because they tho...</td>\n",
       "      <td>psy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z12msjqximryxdfz104cjhbhtw2ld5ipsh4</td>\n",
       "      <td>SIR JOHN</td>\n",
       "      <td>2015-05-07 02:28:12.704</td>\n",
       "      <td>EMINEM the best EVER.﻿</td>\n",
       "      <td>eminem</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              COMMENT_ID                    AUTHOR  \\\n",
       "0  z13ozdmr4lf3uzc5z04cix2zkyjzgvcyemw0k           Carlos Thegamer   \n",
       "1    z13aznjg2ojwjlknm23yjbt4uniuepuxs04            Dunrell Pinder   \n",
       "2      z12kil5h2ujlyzgnc23qtzqyokqrc3301  Sinaloence LiveUniverseI   \n",
       "3  z13vhvu54u3ewpp5h04ccb4zuoardrmjlyk0k                Ray Benich   \n",
       "4    z12msjqximryxdfz104cjhbhtw2ld5ipsh4                  SIR JOHN   \n",
       "\n",
       "                     DATE                                            CONTENT  \\\n",
       "0 2013-12-01 01:20:21.000                 subscribe to my channel people :D﻿   \n",
       "1 2015-05-23 02:57:54.433                                        i love her﻿   \n",
       "2 2015-04-29 03:58:06.452            I like This Comment and do not kill :P﻿   \n",
       "3 2015-06-05 18:05:16.000  The first billion viewed this because they tho...   \n",
       "4 2015-05-07 02:28:12.704                             EMINEM the best EVER.﻿   \n",
       "\n",
       "  INTERPRET  00  000  002  018  02  ...  ｃｏｍｍｅｎｔ  ｄａｍｎ  ｅｂａｙ  ｆａｎｃy  ｈｔｔｐ  ｉｓ  \\\n",
       "0       psy   0    0    0    0   0  ...        0     0     0      0     0   0   \n",
       "1   shakira   0    0    0    0   0  ...        0     0     0      0     0   0   \n",
       "2     lmfao   0    0    0    0   0  ...        0     0     0      0     0   0   \n",
       "3       psy   0    0    0    0   0  ...        0     0     0      0     0   0   \n",
       "4    eminem   0    0    0    0   0  ...        0     0     0      0     0   0   \n",
       "\n",
       "   ｓｈｏｅｃｏｌｌｅｃｔｏｒ314  ｔｈｉｓ  ｕｓｒ  ｗｗｗ  \n",
       "0                 0     0    0    0  \n",
       "1                 0     0    0    0  \n",
       "2                 0     0    0    0  \n",
       "3                 0     0    0    0  \n",
       "4                 0     0    0    0  \n",
       "\n",
       "[5 rows x 3103 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ContentCountVectorizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Applies CountVectorizer on `CONTENT` column\n",
    "    and appends the results to the dataframe.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vectorizer = CountVectorizer()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.vectorizer.fit(X[\"CONTENT\"])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        vectorized = self.vectorizer.transform(X[\"CONTENT\"]) \n",
    "        vectorized_df = pd.DataFrame(vectorized.todense(), columns=self.vectorizer.get_feature_names())\n",
    "        return pd.concat([X, vectorized_df], axis=1)\n",
    "\n",
    "    \n",
    "# DEMO\n",
    "content_vectorizer = ContentCountVectorizer()\n",
    "content_vectorizer.fit(train_X, train_y)\n",
    "transformed = content_vectorizer.transform(test_X)\n",
    "transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-geneva",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-district",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ib031] *",
   "language": "python",
   "name": "conda-env-ib031-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
