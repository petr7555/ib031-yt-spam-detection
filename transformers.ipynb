{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "level-teacher",
   "metadata": {},
   "source": [
    "# Transformers library\n",
    "We will take advantage of custom transformers. This way, it is easy to use them in pipelines both for training and testing. We can easily select a subset of transformations and vary transformations based on used model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "convinced-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local\n",
    "from ipynb.fs.full.data_loader import load_train_test_all_cols_data\n",
    "\n",
    "# Math and data stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Language stuff\n",
    "from pymagnitude import Magnitude, MagnitudeUtils\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "\n",
    "# Other\n",
    "import html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-demonstration",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "outstanding-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = load_train_test_all_cols_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-vietnam",
   "metadata": {},
   "source": [
    "## DenseTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cognitive-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseTransformer(TransformerMixin):\n",
    "    \"\"\"\n",
    "    Makes sparse arrays dense.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense() # toarray() works too"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-fleet",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-dependence",
   "metadata": {},
   "source": [
    "## FeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "broken-vegetarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>Sonny Carter</td>\n",
       "      <td>2015-05-22 11:46:35.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>Lizzy Molly</td>\n",
       "      <td>2013-09-09 17:34:07.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>Warcorpse666</td>\n",
       "      <td>2015-05-26 02:27:43.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>Santeri Saariokari</td>\n",
       "      <td>2014-09-03 16:32:59.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>Quinho Divulgaçoes</td>\n",
       "      <td>2014-11-06 19:50:16.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AUTHOR                    DATE\n",
       "1447        Sonny Carter 2015-05-22 11:46:35.988\n",
       "1846         Lizzy Molly 2013-09-09 17:34:07.052\n",
       "1304        Warcorpse666 2015-05-26 02:27:43.254\n",
       "402   Santeri Saariokari 2014-09-03 16:32:59.000\n",
       "652   Quinho Divulgaçoes 2014-11-06 19:50:16.000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Selects a subset of features based on column names or data type.\n",
    "    If both `columns` and `dtype_include` are given, union of selected columns is returned.\n",
    "    \"\"\"\n",
    "    def __init__(self, columns=[], dtype_include=None):\n",
    "        self.columns = columns\n",
    "        self.dtype_include = dtype_include\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        if self.dtype_include is not None:\n",
    "            self.columns.extend(X.select_dtypes(self.dtype_include).columns)\n",
    "        return X[set(self.columns)]\n",
    "\n",
    "# DEMO 1\n",
    "transformed = FeatureSelector([\"AUTHOR\", \"DATE\"]).transform(train_X)\n",
    "transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "laden-stroke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>INTERPRET</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>z13wxtdpeznid12et23ogtd4zoyvzbnoz04</td>\n",
       "      <td>eminem</td>\n",
       "      <td>Sonny Carter</td>\n",
       "      <td>I love this song sooooooooooooooo much﻿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>_2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY</td>\n",
       "      <td>shakira</td>\n",
       "      <td>Lizzy Molly</td>\n",
       "      <td>PLEASE CHECK OUT MY VIDEO CALLED &amp;quot;WE LOVE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>z13uutbriumnuj3rq04ccbvqlwjuj1srhyk0k</td>\n",
       "      <td>eminem</td>\n",
       "      <td>Warcorpse666</td>\n",
       "      <td>sorry but eminmem is a worthless wife beating ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>z121gbuy2unhc5m4n04cf3kyslqhepeqgvo0k</td>\n",
       "      <td>katy</td>\n",
       "      <td>Santeri Saariokari</td>\n",
       "      <td>Hey guys go to check my video name \"growtopia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>z133hdqrqpukup0lp22chhoaztrhvxov5</td>\n",
       "      <td>katy</td>\n",
       "      <td>Quinho Divulgaçoes</td>\n",
       "      <td>me segue ha  https://www.facebook.com/marcos.s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       COMMENT_ID INTERPRET  \\\n",
       "1447          z13wxtdpeznid12et23ogtd4zoyvzbnoz04    eminem   \n",
       "1846  _2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY   shakira   \n",
       "1304        z13uutbriumnuj3rq04ccbvqlwjuj1srhyk0k    eminem   \n",
       "402         z121gbuy2unhc5m4n04cf3kyslqhepeqgvo0k      katy   \n",
       "652             z133hdqrqpukup0lp22chhoaztrhvxov5      katy   \n",
       "\n",
       "                  AUTHOR                                            CONTENT  \n",
       "1447        Sonny Carter            I love this song sooooooooooooooo much﻿  \n",
       "1846         Lizzy Molly  PLEASE CHECK OUT MY VIDEO CALLED &quot;WE LOVE...  \n",
       "1304        Warcorpse666  sorry but eminmem is a worthless wife beating ...  \n",
       "402   Santeri Saariokari  Hey guys go to check my video name \"growtopia ...  \n",
       "652   Quinho Divulgaçoes  me segue ha  https://www.facebook.com/marcos.s...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEMO 2\n",
    "transformed = FeatureSelector(dtype_include=\"string\").transform(train_X)\n",
    "transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-portrait",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-franklin",
   "metadata": {},
   "source": [
    "## WordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "several-target",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 30, 300)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class WordEmbeddingsSeries(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    ! Works with Series, not DataFrame !\n",
    "    For each row in series, which contains a sentence, \n",
    "    it embeds the words in the series into 300 dimensional vectors (one vector for each word).\n",
    "    \"\"\"\n",
    "    def __init__(self, vectors):\n",
    "        super().__init__()\n",
    "        self.vectors = vectors\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        tokenized = [word_tokenize(line) for line in X]\n",
    "        return self.vectors.query(tokenized)\n",
    "    \n",
    "# DEMO\n",
    "vectors = Magnitude(MagnitudeUtils.download_model('fasttext/medium/wiki-news-300d-1M'), pad_to_length=30)\n",
    "transformed = WordEmbeddingsSeries(vectors).transform(train_X[\"CONTENT\"][:20])\n",
    "transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-sunset",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-ranking",
   "metadata": {},
   "source": [
    "## WordEmbeddingsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "competitive-congo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1249, 602)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class WordEmbeddingsDF(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    For each column (given in constructor or all columns if not specified),\n",
    "    computes word embedddings of values in the column split with nltk.word_tokenize.\n",
    "    The mean of these word embeddings is then computed, giving 300 dimensional vector for each row.\n",
    "    This vector is then appended to the dataframe as 300 new columns.\n",
    "    \"\"\"\n",
    "    def __init__(self, columns=None):\n",
    "        super().__init__()\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        i = 0\n",
    "        # encode all columns by default\n",
    "        if self.columns is None:\n",
    "            self.columns = X.columns\n",
    "\n",
    "        for col in self.columns:\n",
    "            tokenized = [word_tokenize(line) for line in X[col]]\n",
    "            mean = np.mean(vectors.query(tokenized), axis=1)\n",
    "            for j in range(300):\n",
    "                X[f\"{i}_EMBEDDED\"] = mean[:,j]\n",
    "                i += 1\n",
    "                \n",
    "        return X\n",
    "    \n",
    "transformed = WordEmbeddingsDF().transform(train_X[[\"AUTHOR\", \"CONTENT\"]])\n",
    "transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-internship",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-organization",
   "metadata": {},
   "source": [
    "## ExplorativeTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "digital-flashing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>INTERPRET</th>\n",
       "      <th>HAS_LINK</th>\n",
       "      <th>NOT_UNIQUE_AUTHOR</th>\n",
       "      <th>NULL_IN_DATE_TIME</th>\n",
       "      <th>SUSPICIOUS_WORDS_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>z13wxtdpeznid12et23ogtd4zoyvzbnoz04</td>\n",
       "      <td>Sonny Carter</td>\n",
       "      <td>2015-05-22 11:46:35.988</td>\n",
       "      <td>I love this song sooooooooooooooo much﻿</td>\n",
       "      <td>eminem</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>_2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY</td>\n",
       "      <td>Lizzy Molly</td>\n",
       "      <td>2013-09-09 17:34:07.052</td>\n",
       "      <td>PLEASE CHECK OUT MY VIDEO CALLED &amp;quot;WE LOVE...</td>\n",
       "      <td>shakira</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>z13uutbriumnuj3rq04ccbvqlwjuj1srhyk0k</td>\n",
       "      <td>Warcorpse666</td>\n",
       "      <td>2015-05-26 02:27:43.254</td>\n",
       "      <td>sorry but eminmem is a worthless wife beating ...</td>\n",
       "      <td>eminem</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>z121gbuy2unhc5m4n04cf3kyslqhepeqgvo0k</td>\n",
       "      <td>Santeri Saariokari</td>\n",
       "      <td>2014-09-03 16:32:59.000</td>\n",
       "      <td>Hey guys go to check my video name \"growtopia ...</td>\n",
       "      <td>katy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>z133hdqrqpukup0lp22chhoaztrhvxov5</td>\n",
       "      <td>Quinho Divulgaçoes</td>\n",
       "      <td>2014-11-06 19:50:16.000</td>\n",
       "      <td>me segue ha  https://www.facebook.com/marcos.s...</td>\n",
       "      <td>katy</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       COMMENT_ID              AUTHOR  \\\n",
       "1447          z13wxtdpeznid12et23ogtd4zoyvzbnoz04        Sonny Carter   \n",
       "1846  _2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY         Lizzy Molly   \n",
       "1304        z13uutbriumnuj3rq04ccbvqlwjuj1srhyk0k        Warcorpse666   \n",
       "402         z121gbuy2unhc5m4n04cf3kyslqhepeqgvo0k  Santeri Saariokari   \n",
       "652             z133hdqrqpukup0lp22chhoaztrhvxov5  Quinho Divulgaçoes   \n",
       "\n",
       "                        DATE  \\\n",
       "1447 2015-05-22 11:46:35.988   \n",
       "1846 2013-09-09 17:34:07.052   \n",
       "1304 2015-05-26 02:27:43.254   \n",
       "402  2014-09-03 16:32:59.000   \n",
       "652  2014-11-06 19:50:16.000   \n",
       "\n",
       "                                                CONTENT INTERPRET  HAS_LINK  \\\n",
       "1447            I love this song sooooooooooooooo much﻿    eminem         0   \n",
       "1846  PLEASE CHECK OUT MY VIDEO CALLED &quot;WE LOVE...   shakira         0   \n",
       "1304  sorry but eminmem is a worthless wife beating ...    eminem         0   \n",
       "402   Hey guys go to check my video name \"growtopia ...      katy         0   \n",
       "652   me segue ha  https://www.facebook.com/marcos.s...      katy         2   \n",
       "\n",
       "      NOT_UNIQUE_AUTHOR  NULL_IN_DATE_TIME  SUSPICIOUS_WORDS_COUNT  \n",
       "1447                  0                  0                       0  \n",
       "1846                  0                  0                       3  \n",
       "1304                  0                  0                       0  \n",
       "402                   0                  0                       3  \n",
       "652                   0                  0                       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ExplorativeTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.duplicated_and_spammers = 0\n",
    "        self.duplicated_and_not_spammers = 0\n",
    "        self.not_unique_authors = set()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        \n",
    "        stop = stopwords.words('english')\n",
    "\n",
    "        author_set = set()\n",
    "        for author in X[\"AUTHOR\"]:\n",
    "            if author in author_set:\n",
    "                self.not_unique_authors.add(author)\n",
    "            author_set.add(author)\n",
    "            \n",
    "        # are all duplicated authors spammers?\n",
    "        for index, row in X.iterrows():\n",
    "            if row[\"AUTHOR\"] in self.not_unique_authors and y[index] == 1:\n",
    "                self.duplicated_and_spammers += 1\n",
    "            if row[\"AUTHOR\"] in self.not_unique_authors and y[index] == 0:\n",
    "                self.duplicated_and_not_spammers += 1\n",
    "        \n",
    "        \"\"\"\n",
    "        Creates 2 dictionaries: spam_dic and ham_dict, one that counts occurence of each word in spam comments, \n",
    "        other counts occurence of each word in ham comments.\n",
    "        Further, only those words that are repeated more than 15 times are left in ham_dict, \n",
    "        and those repeated more than 35 times in spam_dict.\n",
    "        Numbers are chosen like that, because I wanted to empahsise, that it is more importatnt to not mark as spam sth.,\n",
    "        that is not spam, than the other way around.\n",
    "        The last step is to keep only those words in spam_dict that are not in ham_dict and are not stop_words.\n",
    "        \"\"\"\n",
    "\n",
    "        self.spam_dict = self.get_suspicious_words(X, y, 1)\n",
    "        ham_dict = self.get_suspicious_words(X, y, 0)\n",
    "        my_inverted_dict_spam = dict(map(reversed, self.spam_dict.items()))\n",
    "        my_inverted_dict_ham = dict(map(reversed, ham_dict.items()))\n",
    "        suspicious_spam = []\n",
    "        suspicious_ham = []\n",
    "\n",
    "        for key in my_inverted_dict_spam:\n",
    "            if key > 15 and my_inverted_dict_spam[key] not in stop:\n",
    "                suspicious_spam.append(my_inverted_dict_spam[key])\n",
    "\n",
    "        for key in my_inverted_dict_ham:\n",
    "            if key > 35 and my_inverted_dict_ham[key] not in stop:\n",
    "                suspicious_ham.append(my_inverted_dict_ham[key])\n",
    "\n",
    "        # remove all from spam that is in ham\n",
    "        self.suspicious_words_list = []\n",
    "        for word in suspicious_spam:\n",
    "            if word not in suspicious_ham:\n",
    "                self.suspicious_words_list.append(word)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"HAS_LINK\"] = np.where(X['CONTENT'].str.contains('http') |\n",
    "                                  X['CONTENT'].str.contains('//'), 2, 0)\n",
    "    \n",
    "        X[\"NOT_UNIQUE_AUTHOR\"] = np.where(X['AUTHOR'].str in self.not_unique_authors, self.duplicated_and_not_spammers\n",
    "                                           // self.duplicated_and_spammers, 0)\n",
    "\n",
    "        X[\"NULL_IN_DATE_TIME\"] = np.where(X[\"DATE\"].isna(), 2, 0)\n",
    "                \n",
    "        result = []\n",
    "        for index, row in X.iterrows():\n",
    "            suspicious_counter = 0\n",
    "            for word in self.suspicious_words_list:\n",
    "                my_row = row[\"CONTENT\"].lower().split()\n",
    "                if word in my_row:\n",
    "                    suspicious_counter += self.spam_dict[word.lower()] // 100\n",
    "            result.append(suspicious_counter)\n",
    "\n",
    "        X[\"SUSPICIOUS_WORDS_COUNT\"] = result\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def get_suspicious_words(self, X, y, num):\n",
    "        result = {}\n",
    "        for index, row in X.iterrows():\n",
    "            if y[index] != num:\n",
    "                continue\n",
    "            words = (row[\"CONTENT\"].lower()).split()\n",
    "            for word in words:\n",
    "                if word in result:\n",
    "                    result[word] += 1\n",
    "                else:\n",
    "                    result[word] = 1\n",
    "                    \n",
    "        return result\n",
    "\n",
    "# DEMO\n",
    "transformed = ExplorativeTransformer().fit_transform(train_X, train_y)\n",
    "transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-killer",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-speaking",
   "metadata": {},
   "source": [
    "## AddMissingDateColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "postal-network",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>INTERPRET</th>\n",
       "      <th>DATE_MISSING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>_2viQ_Qnc6_FlLJN0izQaKVQNe6LGDmPZMmkVDjjymE</td>\n",
       "      <td>Neeru bala</td>\n",
       "      <td>2013-09-05 23:07:09.056</td>\n",
       "      <td>Hi.. Everyone.. If anyone after real online wo...</td>\n",
       "      <td>shakira</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>LneaDw26bFsltJodWnZAafXscqrATBuKDM8-8lA4TQE</td>\n",
       "      <td>miamiscraziest</td>\n",
       "      <td>NaT</td>\n",
       "      <td>LADIES!!! -----&amp;gt;&amp;gt; If you have a broken h...</td>\n",
       "      <td>eminem</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       COMMENT_ID          AUTHOR  \\\n",
       "1865  _2viQ_Qnc6_FlLJN0izQaKVQNe6LGDmPZMmkVDjjymE      Neeru bala   \n",
       "1427  LneaDw26bFsltJodWnZAafXscqrATBuKDM8-8lA4TQE  miamiscraziest   \n",
       "\n",
       "                        DATE  \\\n",
       "1865 2013-09-05 23:07:09.056   \n",
       "1427                     NaT   \n",
       "\n",
       "                                                CONTENT INTERPRET  \\\n",
       "1865  Hi.. Everyone.. If anyone after real online wo...   shakira   \n",
       "1427  LADIES!!! -----&gt;&gt; If you have a broken h...    eminem   \n",
       "\n",
       "      DATE_MISSING  \n",
       "1865         False  \n",
       "1427          True  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AddMissingDateColumn(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Adds boolean column if DATE value is missing.\n",
    "    The model should then understand that True most likely means spam.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # do not modify the original dataset\n",
    "        X = X.copy()\n",
    "        X[\"DATE_MISSING\"] = X.DATE.isna()\n",
    "        return X\n",
    "    \n",
    "# DEMO\n",
    "transformed = AddMissingDateColumn().transform(train_X)\n",
    "transformed[1244:1246]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-benchmark",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-symphony",
   "metadata": {},
   "source": [
    "## AddLongCommentColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "passive-sheriff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>INTERPRET</th>\n",
       "      <th>LONG_COMMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>z13wxtdpeznid12et23ogtd4zoyvzbnoz04</td>\n",
       "      <td>Sonny Carter</td>\n",
       "      <td>2015-05-22 11:46:35.988</td>\n",
       "      <td>I love this song sooooooooooooooo much﻿</td>\n",
       "      <td>eminem</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>_2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY</td>\n",
       "      <td>Lizzy Molly</td>\n",
       "      <td>2013-09-09 17:34:07.052</td>\n",
       "      <td>PLEASE CHECK OUT MY VIDEO CALLED &amp;quot;WE LOVE...</td>\n",
       "      <td>shakira</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       COMMENT_ID        AUTHOR  \\\n",
       "1447          z13wxtdpeznid12et23ogtd4zoyvzbnoz04  Sonny Carter   \n",
       "1846  _2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY   Lizzy Molly   \n",
       "\n",
       "                        DATE  \\\n",
       "1447 2015-05-22 11:46:35.988   \n",
       "1846 2013-09-09 17:34:07.052   \n",
       "\n",
       "                                                CONTENT INTERPRET  \\\n",
       "1447            I love this song sooooooooooooooo much﻿    eminem   \n",
       "1846  PLEASE CHECK OUT MY VIDEO CALLED &quot;WE LOVE...   shakira   \n",
       "\n",
       "      LONG_COMMENT  \n",
       "1447         False  \n",
       "1846          True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AddLongCommentColumn(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Adds boolean column if CONTENT is longer or equal to 50 charcters.\n",
    "    The model should then understand that True most likely means spam.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"LONG_COMMENT\"] = X.CONTENT.str.len() >= 50\n",
    "        return X\n",
    "\n",
    "# DEMO\n",
    "transformed = AddLongCommentColumn().transform(train_X)\n",
    "transformed[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-hypothetical",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-lawyer",
   "metadata": {},
   "source": [
    "## AddContainsCheckColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "numerical-diagram",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>INTERPRET</th>\n",
       "      <th>CONTAINS_CHECK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>z13uutbriumnuj3rq04ccbvqlwjuj1srhyk0k</td>\n",
       "      <td>Warcorpse666</td>\n",
       "      <td>2015-05-26 02:27:43.254</td>\n",
       "      <td>sorry but eminmem is a worthless wife beating ...</td>\n",
       "      <td>eminem</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>z121gbuy2unhc5m4n04cf3kyslqhepeqgvo0k</td>\n",
       "      <td>Santeri Saariokari</td>\n",
       "      <td>2014-09-03 16:32:59.000</td>\n",
       "      <td>Hey guys go to check my video name \"growtopia ...</td>\n",
       "      <td>katy</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 COMMENT_ID              AUTHOR  \\\n",
       "1304  z13uutbriumnuj3rq04ccbvqlwjuj1srhyk0k        Warcorpse666   \n",
       "402   z121gbuy2unhc5m4n04cf3kyslqhepeqgvo0k  Santeri Saariokari   \n",
       "\n",
       "                        DATE  \\\n",
       "1304 2015-05-26 02:27:43.254   \n",
       "402  2014-09-03 16:32:59.000   \n",
       "\n",
       "                                                CONTENT INTERPRET  \\\n",
       "1304  sorry but eminmem is a worthless wife beating ...    eminem   \n",
       "402   Hey guys go to check my video name \"growtopia ...      katy   \n",
       "\n",
       "      CONTAINS_CHECK  \n",
       "1304           False  \n",
       "402             True  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AddContainsCheckColumn(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Adds boolean column if CONTENT contains 'check'.\n",
    "    The model should then understand that True most likely means spam.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"CONTAINS_CHECK\"] = X.CONTENT.str.contains(\"check\")\n",
    "        return X\n",
    "\n",
    "# DEMO\n",
    "transformed = AddContainsCheckColumn().transform(train_X)\n",
    "transformed[2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-marriage",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-round",
   "metadata": {},
   "source": [
    "## AddMultipleCommentsColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "twenty-disclaimer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>INTERPRET</th>\n",
       "      <th>MULTIPLE_COMMENTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>_2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY</td>\n",
       "      <td>Lizzy Molly</td>\n",
       "      <td>2013-09-09 17:34:07.052</td>\n",
       "      <td>PLEASE CHECK OUT MY VIDEO CALLED &amp;quot;WE LOVE...</td>\n",
       "      <td>shakira</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       COMMENT_ID       AUTHOR  \\\n",
       "1846  _2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY  Lizzy Molly   \n",
       "\n",
       "                        DATE  \\\n",
       "1846 2013-09-09 17:34:07.052   \n",
       "\n",
       "                                                CONTENT INTERPRET  \\\n",
       "1846  PLEASE CHECK OUT MY VIDEO CALLED &quot;WE LOVE...   shakira   \n",
       "\n",
       "      MULTIPLE_COMMENTS  \n",
       "1846              False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AddMultipleCommentsColumn(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Adds boolean column if author posted multiple comments.\n",
    "    The model should then understand that True most likely means spam.\n",
    "    \n",
    "    Looks also into data it has been fit on.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.prev_X = X.copy()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        joined = pd.concat([X, self.prev_X])\n",
    "        joined.drop_duplicates(inplace=True)\n",
    "        X[\"MULTIPLE_COMMENTS\"] = joined.duplicated(subset=[\"AUTHOR\"], keep=False)[:len(X)]\n",
    "        return X\n",
    "    \n",
    "# DEMO\n",
    "mollys = train_X[train_X.AUTHOR == \"Lizzy Molly\"]\n",
    "admc = AddMultipleCommentsColumn()\n",
    "admc.fit_transform(mollys[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "skilled-foster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>INTERPRET</th>\n",
       "      <th>MULTIPLE_COMMENTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>LneaDw26bFuhuiZ8uX6C-qYLIsOFj9BIWtKWtCz870c</td>\n",
       "      <td>Lizzy Molly</td>\n",
       "      <td>NaT</td>\n",
       "      <td>PLEASE CHECK OUT MY VIDEO CALLED &amp;quot;WE LOVE...</td>\n",
       "      <td>eminem</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       COMMENT_ID       AUTHOR DATE  \\\n",
       "1472  LneaDw26bFuhuiZ8uX6C-qYLIsOFj9BIWtKWtCz870c  Lizzy Molly  NaT   \n",
       "\n",
       "                                                CONTENT INTERPRET  \\\n",
       "1472  PLEASE CHECK OUT MY VIDEO CALLED &quot;WE LOVE...    eminem   \n",
       "\n",
       "      MULTIPLE_COMMENTS  \n",
       "1472               True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = admc.transform(mollys[1:2])\n",
    "transformed[transformed.AUTHOR == \"Lizzy Molly\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-proceeding",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-pointer",
   "metadata": {},
   "source": [
    "## AddMultipleCommentsSameVideoColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "durable-satin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>INTERPRET</th>\n",
       "      <th>MULTIPLE_COMMENTS_SAME_VIDEO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>_2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY</td>\n",
       "      <td>Lizzy Molly</td>\n",
       "      <td>2013-09-09 17:34:07.052</td>\n",
       "      <td>PLEASE CHECK OUT MY VIDEO CALLED &amp;quot;WE LOVE...</td>\n",
       "      <td>shakira</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>LneaDw26bFuhuiZ8uX6C-qYLIsOFj9BIWtKWtCz870c</td>\n",
       "      <td>Lizzy Molly</td>\n",
       "      <td>NaT</td>\n",
       "      <td>PLEASE CHECK OUT MY VIDEO CALLED &amp;quot;WE LOVE...</td>\n",
       "      <td>eminem</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       COMMENT_ID       AUTHOR  \\\n",
       "1846  _2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY  Lizzy Molly   \n",
       "1472  LneaDw26bFuhuiZ8uX6C-qYLIsOFj9BIWtKWtCz870c  Lizzy Molly   \n",
       "\n",
       "                        DATE  \\\n",
       "1846 2013-09-09 17:34:07.052   \n",
       "1472                     NaT   \n",
       "\n",
       "                                                CONTENT INTERPRET  \\\n",
       "1846  PLEASE CHECK OUT MY VIDEO CALLED &quot;WE LOVE...   shakira   \n",
       "1472  PLEASE CHECK OUT MY VIDEO CALLED &quot;WE LOVE...    eminem   \n",
       "\n",
       "      MULTIPLE_COMMENTS_SAME_VIDEO  \n",
       "1846                         False  \n",
       "1472                         False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AddMultipleCommentsSameVideoColumn(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Adds boolean column if author posted multiple comments for the same video.\n",
    "    The model should then understand that True most likely means spam.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"MULTIPLE_COMMENTS_SAME_VIDEO\"] = X.duplicated(subset=[\"AUTHOR\", \"INTERPRET\"], keep=False)\n",
    "        return X\n",
    "    \n",
    "# DEMO    \n",
    "transformed = AddMultipleCommentsSameVideoColumn().transform(train_X)\n",
    "transformed[transformed.AUTHOR == \"Lizzy Molly\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-contribution",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-vegetarian",
   "metadata": {},
   "source": [
    "## AddContainsHttpColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "civilian-monitoring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>INTERPRET</th>\n",
       "      <th>CONTAINS_HTTP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>z121gbuy2unhc5m4n04cf3kyslqhepeqgvo0k</td>\n",
       "      <td>Santeri Saariokari</td>\n",
       "      <td>2014-09-03 16:32:59</td>\n",
       "      <td>Hey guys go to check my video name \"growtopia ...</td>\n",
       "      <td>katy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>z133hdqrqpukup0lp22chhoaztrhvxov5</td>\n",
       "      <td>Quinho Divulgaçoes</td>\n",
       "      <td>2014-11-06 19:50:16</td>\n",
       "      <td>me segue ha  https://www.facebook.com/marcos.s...</td>\n",
       "      <td>katy</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                COMMENT_ID              AUTHOR  \\\n",
       "402  z121gbuy2unhc5m4n04cf3kyslqhepeqgvo0k  Santeri Saariokari   \n",
       "652      z133hdqrqpukup0lp22chhoaztrhvxov5  Quinho Divulgaçoes   \n",
       "\n",
       "                   DATE                                            CONTENT  \\\n",
       "402 2014-09-03 16:32:59  Hey guys go to check my video name \"growtopia ...   \n",
       "652 2014-11-06 19:50:16  me segue ha  https://www.facebook.com/marcos.s...   \n",
       "\n",
       "    INTERPRET  CONTAINS_HTTP  \n",
       "402      katy          False  \n",
       "652      katy           True  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AddContainsHttpColumn(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Adds boolean column if CONTENT contains a link.\n",
    "    The model should then understand that True most likely means spam.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"CONTAINS_HTTP\"] = X.CONTENT.str.contains(\"http\")\n",
    "        return X\n",
    "    \n",
    "# DEMO    \n",
    "transformed = AddContainsHttpColumn().transform(train_X)\n",
    "transformed[3:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-seeker",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-sample",
   "metadata": {},
   "source": [
    "## AddTimeColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stable-compound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>INTERPRET</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>z13wxtdpeznid12et23ogtd4zoyvzbnoz04</td>\n",
       "      <td>Sonny Carter</td>\n",
       "      <td>2015-05-22 11:46:35.988</td>\n",
       "      <td>I love this song sooooooooooooooo much﻿</td>\n",
       "      <td>eminem</td>\n",
       "      <td>11:46:35.988000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               COMMENT_ID        AUTHOR  \\\n",
       "1447  z13wxtdpeznid12et23ogtd4zoyvzbnoz04  Sonny Carter   \n",
       "\n",
       "                        DATE                                  CONTENT  \\\n",
       "1447 2015-05-22 11:46:35.988  I love this song sooooooooooooooo much﻿   \n",
       "\n",
       "     INTERPRET             TIME  \n",
       "1447    eminem  11:46:35.988000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AddTimeColumn(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Adds time column.\n",
    "    Hypothesis: spams are posted at night, or, on the contrary, spams are posted during main working hours. Let the model decide...\n",
    "    This probably won't work, because the dates are most likely relative to the time zone, where they were collected.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"TIME\"] = X.DATE.dt.time\n",
    "        return X\n",
    "    \n",
    "# DEMO    \n",
    "transformed = AddTimeColumn().transform(train_X)\n",
    "transformed[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-exploration",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-question",
   "metadata": {},
   "source": [
    "## HtmlUnescaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "posted-standing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  <a href=\"http://www.youtube.com/watch?v=KQ6zr6kCPj8&amp;t=2m19s\">2:19</a> best part﻿\n",
      "After:  <a href=\"http://www.youtube.com/watch?v=KQ6zr6kCPj8&t=2m19s\">2:19</a> best part﻿\n"
     ]
    }
   ],
   "source": [
    "class HtmlUnescaper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    For example, `&amp;` is escaped ampersand. Unescape it and other characters as well.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"CONTENT\"] = X[\"CONTENT\"].apply(html.unescape)\n",
    "        return X\n",
    "    \n",
    "# DEMO    \n",
    "print(\"Before: \", train_X.CONTENT[700])\n",
    "transformed = HtmlUnescaper().transform(train_X)\n",
    "print(\"After: \", transformed.CONTENT[700])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-architect",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-filing",
   "metadata": {},
   "source": [
    "## BOMRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "advanced-singing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Before: <a href=\"http://www.youtube.com/watch?v=KQ6zr6kCPj8&amp;t=2m19s\">2:19</a> best part\\ufeff'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BOMRemover(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Remove Byte Order Mark from comments.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"CONTENT\"] = X[\"CONTENT\"].str.replace(\"\\ufeff\", \"\", regex=False)\n",
    "        return X\n",
    "\n",
    "# DEMO\n",
    "\"Before: \" + train_X.CONTENT.loc[700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mechanical-diesel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'After: <a href=\"http://www.youtube.com/watch?v=KQ6zr6kCPj8&amp;t=2m19s\">2:19</a> best part'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = BOMRemover().transform(train_X)\n",
    "\"After: \" + transformed.CONTENT.loc[700]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-alabama",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-advice",
   "metadata": {},
   "source": [
    "## AnchorTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "everyday-navigator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: <a href=\"http://www.youtube.com/watch?v=KQ6zr6kCPj8&amp;t=2m19s\">2:19</a> best part﻿\n",
      "After: anchortag best part﻿\n"
     ]
    }
   ],
   "source": [
    "class AnchorTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transforms all anchor tags into one keyword. \n",
    "    The model will figure out, that the presence of this keyword probably means spam.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"CONTENT\"] = X[\"CONTENT\"].str.replace(\"<a.+>\", \"anchortag\", regex=True)\n",
    "        return X\n",
    "    \n",
    "# DEMO\n",
    "print(\"Before: \" + train_X.CONTENT.loc[700])\n",
    "transformed = AnchorTransformer().transform(train_X)\n",
    "print(\"After: \" + transformed.CONTENT.loc[700])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-geography",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-copying",
   "metadata": {},
   "source": [
    "## AddContainsAnchorTagColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "shared-likelihood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: <a href=\"http://www.youtube.com/watch?v=KQ6zr6kCPj8&amp;t=2m19s\">2:19</a> best part﻿\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "COMMENT_ID             z13uwn2heqndtr5g304ccv5j5kqqzxjadmc0k\n",
       "AUTHOR                                          Corey Wilson\n",
       "DATE                              2015-05-28 21:39:52.376000\n",
       "CONTENT                                           best part﻿\n",
       "INTERPRET                                              lmfao\n",
       "CONTAINS_ANCHOR_TAG                                     True\n",
       "Name: 700, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AddContainsAnchorTagColumn(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Adds new column CONTAINS_ANCHOR_TAG which is True when CONTENT contains <a> tag.\n",
    "    The model should then understand that True most likely means spam.\n",
    "    Removes the link from CONTENT as well.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"CONTAINS_ANCHOR_TAG\"] = X[\"CONTENT\"].str.contains(\"<a.+>\")\n",
    "        X[\"CONTENT\"] = X[\"CONTENT\"].str.replace(\"<a.+>\", \"\", regex=True)\n",
    "        return X\n",
    "    \n",
    "# DEMO\n",
    "print(\"Before: \" + train_X.CONTENT.loc[700])\n",
    "transformed = AddContainsAnchorTagColumn().transform(train_X)\n",
    "transformed.loc[700]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-arthritis",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-apple",
   "metadata": {},
   "source": [
    "## Lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "pacific-sheep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: People, here is a new network like FB...\n",
      "After: people, here is a new network like fb...\n"
     ]
    }
   ],
   "source": [
    "class Lower(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Makes CONTENT lowercase.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"CONTENT\"] = X[\"CONTENT\"].str.lower()\n",
    "        return X\n",
    "    \n",
    "# DEMO\n",
    "print(\"Before: \" + train_X.CONTENT.loc[192][:40])\n",
    "transformed = Lower().transform(train_X)\n",
    "print(\"After: \" + transformed.CONTENT.loc[192][:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-uzbekistan",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-singing",
   "metadata": {},
   "source": [
    "## UrlTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "rental-remark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: subscribe to my channel  /watch?v=NxK32i0HkDs\n",
      "Before: please like :D https://premium.easypromosapp.com/voteme/19924/616375350﻿\n",
      "After: subscribe to my channel  urllink\n",
      "After: please like :D urllink\n"
     ]
    }
   ],
   "source": [
    "class UrlTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transforms all urls into one keyword. \n",
    "    The model will figure out, that the presence of this keyword probably means spam.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"CONTENT\"] = X[\"CONTENT\"].str.replace(r\"\\S*\\.com\\S*|\\S*watch\\?\\S*\", \"urllink\", regex=True)\n",
    "        return X\n",
    "    \n",
    "# DEMO\n",
    "print(\"Before: \" + train_X.CONTENT.loc[1573])\n",
    "print(\"Before: \" + train_X.CONTENT.loc[14])\n",
    "transformed = UrlTransformer().transform(train_X)\n",
    "print(\"After: \" + transformed.CONTENT.loc[1573])\n",
    "print(\"After: \" + transformed.CONTENT.loc[14])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-queens",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-solution",
   "metadata": {},
   "source": [
    "## Debugger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "chemical-scale",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       COMMENT_ID              AUTHOR  \\\n",
      "1447          z13wxtdpeznid12et23ogtd4zoyvzbnoz04        Sonny Carter   \n",
      "1846  _2viQ_Qnc6-adCzTDLAhqNVQ5hFYcjPyPI5m7pHY4BY         Lizzy Molly   \n",
      "1304        z13uutbriumnuj3rq04ccbvqlwjuj1srhyk0k        Warcorpse666   \n",
      "402         z121gbuy2unhc5m4n04cf3kyslqhepeqgvo0k  Santeri Saariokari   \n",
      "652             z133hdqrqpukup0lp22chhoaztrhvxov5  Quinho Divulgaçoes   \n",
      "\n",
      "                        DATE  \\\n",
      "1447 2015-05-22 11:46:35.988   \n",
      "1846 2013-09-09 17:34:07.052   \n",
      "1304 2015-05-26 02:27:43.254   \n",
      "402  2014-09-03 16:32:59.000   \n",
      "652  2014-11-06 19:50:16.000   \n",
      "\n",
      "                                                CONTENT INTERPRET  \n",
      "1447            I love this song sooooooooooooooo much﻿    eminem  \n",
      "1846  PLEASE CHECK OUT MY VIDEO CALLED &quot;WE LOVE...   shakira  \n",
      "1304  sorry but eminmem is a worthless wife beating ...    eminem  \n",
      "402   Hey guys go to check my video name \"growtopia ...      katy  \n",
      "652   me segue ha  https://www.facebook.com/marcos.s...      katy  \n"
     ]
    }
   ],
   "source": [
    "class Debugger(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Prints head of dataframe\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        print(X.head())\n",
    "        return X\n",
    "    \n",
    "# DEMO\n",
    "transformed = Debugger().transform(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-parcel",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-regulation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ib031] *",
   "language": "python",
   "name": "conda-env-ib031-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
